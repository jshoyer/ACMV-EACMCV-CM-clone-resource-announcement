
This code supports
a resource anouncement paper
describing deep sequencing
of infectious clone plasmids
originally described by Fondong et al. (2000, 2011).
It is released for transparency,
as an aid in understanding the work.
I archived the code
at Zenodo.org
via a forked GitHub repository.
If someone can reuse the code
(after adjusting paths)
that is great,
but that is not the main goal here.
For the data in the Sequence Read Archive,
see https://trace.ncbi.nlm.nih.gov/Traces/study/?acc=SRP274352

Full plasmid sequences
are GenBank accessions MT856192 to 5.
The four sequences are included here as FastA files
for convenience and consistency with the job scripts.
The sequences are “rotated” 3-nt
relative to GenBank.
When I deduced them I set the coordinate system
relative to the ampicillin resistance CDS,
not realizing that I had missed the stop codon,
which later provided inconvenient
when providing annotations to GenBank.

To count reads mapping to the E. coli genome
I included the closest genome to DH5alpha I could find,
GenBank CP001637.1.
To conserve disk space
that sequence is not included in this repository.
The scripts assume that the file is present
and is named 'CP001637.1.fasta'


The Slurm job scripts
are numbered in the order
in which they are to be run,
i.e. submitted with `sbatch`
(010_, 020_, 030_, ...).
The workflow is similar
to the one described
on the [[http://www.htslib.org/workflow/#mapping_to_variant][Samtools workflow page]],
but combines steps with pipes
to reduce repeated disk read/write steps.
Several parts of each script
that need to be edited
are indicated
(UPDATE_HERE).

Indexing of reference sequences
needs to be done just once (015).
The other steps run in parallel,
using a Slurm job array,
with one job per library.
We trim reads with Cutadapt (010),
align them with BWA MEM (020),
and do the processing needed
for calling variants with VarScan.
However, I provide a second option for indexing the reference sequences
(via uncommenting a few lines)
because in reality I indexed the the sequences one at a time,
not all four at once (with the single 015 script).
I indexed a bwa database the first time I ran each script
and then commented the relevant lines out
for the second and third libraries for each plasmid.

FastQ files can be downloaded from the SRA
with the 005_download-data-from-SRA.sh script
which was made with the help
of the online [[https://sra-explorer.info][SRA Explorer]] tool
by Phil Ewels.
Variables in the subsequent job scripts are defined
for the location of those input FastQ files
(FASTQDIR)
and the trimmed read FastQ files
generated from them
(CUTADAPTDIR).
`ls` is used (with `sed`)
to get prefixes from the names of those input files
that are then then used for subsequent output files.
Output from the 02* scripts
could be written to a third directory
(OUTDIR).
Currently a single directory (".")
is used for all of those,
such that all input and output
are assumed to be in the directory
from which the job scripts are run.

Job scripts were run on a cluster
on which Lmod is used to manage software.
If you are not using Lmod
you'll need the relevant binaries (cutadapt, bwa, ...)
to be in your $PATH.

As noted in each job script,
a slurm-logs/ subdirectory must exist
in the directory
in which the scripts are to be run.
I use this method
to avoid cluttering the main output directory
with the STDERR and STDOUT files
that Slurm writes to disk.
