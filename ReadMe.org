
This code supports
a resource anouncement paper
(Hoyer et al. 2020,
 https://doi.org/fhq2)
describing deep sequencing
of infectious clone plasmids
originally described by Fondong et al. (2000, 2011).
I archived the code
at Zenodo.org
(record [[https://zenodo.org/record/4075362][4075362]])
via a GitHub repository.
If someone can reuse the code
(after adjusting paths)
that is great,
but that is not the main goal here.
For the data in the Sequence Read Archive,
see https://trace.ncbi.nlm.nih.gov/Traces/study/?acc=SRP274352

The vector backbone for one plasmid
(ACMV 1.4mer)
was corrected slightly
in GenBank (MT856193.2)
and for third version of Zenodo record:
f1 origin was inverted,
hence backbone was KS(-),
not KS(+).

Relevant sentences from the paper:
    "Reads were trimmed with CutAdapt 1.16
     and aligned to the sequences listed in Table 1
     with the Burrows-Wheeler Aligner (BWA-MEM v0.7.13).
     Variants relative to the reference sequence
     were identified with samtools v1.8
     and VarScan v2.4.4."

Full plasmid sequences
are GenBank accessions MT856192 to 5.
The four sequences are included here as FastA files
for convenience and consistency with the job scripts.
The sequences are “rotated” 3-nt
relative to GenBank.
When I deduced them I set the coordinate system
relative to the ampicillin resistance CDS,
not realizing that I had missed the stop codon,
which later provided inconvenient
when providing annotations to GenBank.

As described in the paper,
ACMV sequences were quite different
from the previously described ones.
The EACMCV virus monomer units
in the two relevant plasmids
were close but not identical
to previously deposited sequences,
with 4 and 2 single-nucleotide differences,
respectively:
#+BEGIN_SRC
EACMCV DNA-A:

MT856195  121   TATTGAGTTTTGACTTTATATACTTCGTCACGAAGTAGTGGAGCGCGTCAAAATGTGGAA  180
                |||||||||||||||||| ||||||||||||||||||||| |||||||||||||||||||
AF112354  128   TATTGAGTTTTGACTTTAAATACTTCGTCACGAAGTAGTGRAGCGCGTCAAAATGTGGAA  187

MT856195  181   T-CCGTTAGTTAACGATTTTCCGGAAA-CCGTTCACGGTTTCCGTTCGATGCTTGCTGTT  238
                | ||||||||||||||||||||||||| ||||||||||||||||||||||||||||||||
AF112354  188   TCCCGTTAGTTAACGATTTTCCGGAAACCCGTTCACGGTTTCCGTTCGATGCTTGCTGTT  247



EACMCV DNA-B:

MT856192  1621  CAGAAGTCTATGCAATCTTTTGTGTATCCCTTGGATAATATGTTGATTGTTGGGGGCTTG  1680
                |||||||||||||||||||||||||||||||||||||||||||||||||| |||||||||
FJ826890  1621  CAGAAGTCTATGCAATCTTTTGTGTATCCCTTGGATAATATGTTGATTGTGGGGGGCTTG  1680

MT856192  2701  ATCTGTGTAATTGCGGCCATCCGAT-TAATATT  2732
                ||||||||||||||||||||||||| |||||||
FJ826890  2701  ATCTGTGTAATTGCGGCCATCCGATTTAATATT  2733
#+END_SRC

To count reads mapping to the E. coli genome
I included the closest genome to DH5alpha I could find,
GenBank CP001637.1.
To conserve disk space
that sequence is not included in this repository.
The scripts assume that the file is present
and is named 'CP001637.1.fasta'
If you have NCBI Entrez Direct e-utilities installed,
you can download this reference like so:
: esearch -db nucleotide -query "CP001637.1" | efetch -format fasta > CP001637.1.fasta


The Slurm job scripts
are numbered in the order
in which they are to be run,
i.e. submitted with `sbatch`
(005 before 010,
 010 and 015 before 02*).
The workflow is similar
to the one described
on the [[http://www.htslib.org/workflow/wgs-call.html][Samtools workflow page]],
but combines steps with pipes
to reduce repeated disk read/write steps.

Indexing of reference sequences
needs to be done just once (015).
The other steps run in parallel,
using a Slurm job array,
with one job per library.
We trim reads with Cutadapt (010),
align them with BWA MEM,
and do the processing needed
for calling variants with VarScan.
The read depth column
is pulled out from mpileup files.

I provide a second option for indexing the reference sequences
(via uncommenting a few lines)
because in reality I indexed the the sequences one at a time,
not all four at once (with the single 015 script).
I indexed a bwa database the first time I ran each script
and then commented the relevant lines out
(and adjusted job array index numbers)
for the second and third libraries for each plasmid.

FastQ files can be downloaded from the SRA
with the 005_download-data-from-SRA.sh script
which was made with the help
of the online [[https://sra-explorer.info][SRA Explorer]] tool
by Phil Ewels.
Variables in the subsequent job scripts are defined
for the location of those input FastQ files
(FASTQDIR)
and the trimmed read FastQ files
generated from them
(CUTADAPTDIR).
`ls` is used (with `sed`)
to get prefixes from the names of those input files
that are then then used for subsequent output files.
Output from the 02* scripts
could be written to a third directory
(OUTDIR).
Currently a single directory (".")
is used for all of those,
such that all input and output
are assumed to be in the directory
from which the job scripts are run.

The R script read-in-and-graph-read-depth-numbers.R
in turn assumes that the read depth tables
are in the current directory,
which is easily changed by editing the relevant variable.
If you use the bash script to download the raw data
you'll have to edit the R script
because it uses table file names
which are derived from the fastq.gz file names,
(originally "AA1_S1" ... "EB3_S12",
 but specified differently in the bash script).
The R script
generates Figure 1 from the paper
(one library per plasmid),
and a more complete set of read depth graphs
(3 libraries × 4 plasmids)

Job scripts were run on a cluster
on which Lmod is used to manage software.
If you are not using Lmod
you'll need the relevant binaries (cutadapt, bwa, fastqc, ...)
to be in your $PATH.

Some lines in each job script (pwd, date, module list)
are included purely to provide context
in the log files.
